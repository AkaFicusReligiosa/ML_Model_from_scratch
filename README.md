
# Building Machine Learning Models From Scratch

This project focuses on building core machine learning models from scratch without using high-level libraries like Scikit-learn for model implementation. The goal is to understand the mathematical intuition and implement the algorithms using only **NumPy and basic Python**.

---

## ðŸ“Œ Algorithms Implemented

1. âœ… **Linear Regression**
   - Built using gradient descent and/or normal equation
   - Evaluation metrics: MSE, RMSE, RÂ² Score

2. âœ… **Logistic Regression**
   - Binary classification using sigmoid function
   - Optimization with gradient descent
   - Evaluation metrics: Accuracy, Precision, Recall, F1-score

3. âœ… **SVM Classifier**
   - Support Vector Machine from scratch using hinge loss
   - Implemented with gradient descent
   - Linear kernel only (optional: add polynomial or RBF)

4. âœ… **Lasso Regression**
   - Linear Regression with L1 regularization
   - Coordinate descent / Gradient Descent method
   - Feature selection capability

---

## ðŸš€ Technologies Used

- Python
- NumPy
- Matplotlib (for visualization)
- Jupyter Notebook

---

## ðŸ§  Project Structure

```

models-from-scratch/
â”‚
â”œâ”€â”€ LinearRegressionScratch.ipynb
â”œâ”€â”€ LogisticRegressionScratch.ipynb
â”œâ”€â”€ SVMClassifierScratch.ipynb
â”œâ”€â”€ LassoRegressionScratch.ipynb
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py      # Common metrics functions
â”‚   â””â”€â”€ visualizer.py   # Optional: plotting functions
â””â”€â”€ data/
â”œâ”€â”€ linear\_data.csv
â”œâ”€â”€ classification\_data.csv

````

---

## ðŸ§ª How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/models-from-scratch.git
   cd models-from-scratch
````

2. Install dependencies:

   ```bash
   pip install numpy matplotlib
   ```

3. Launch the notebook:

   ```bash
   jupyter notebook LinearRegressionScratch.ipynb
   ```

---

## ðŸŽ¯ Learning Outcomes

* Gain hands-on experience with loss functions, gradients, and optimization.
* Understand how models work under the hood.
* Explore regularization and margin-based classifiers without abstraction layers.

---

## ðŸ“œ License

This project is licensed under the **MIT License**.

---

## ðŸ™Œ Acknowledgements

* Inspired by Andrew Ngâ€™s ML course
* Mathematical insights from ISLR & CS229
* Open-source contributors & Python community

```

  
